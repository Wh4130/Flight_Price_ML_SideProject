{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "# Hello"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chrome Driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gl/stf2yn_54sdd_k_jlfmc4nvr0000gn/T/ipykernel_40576/1725469750.py:7: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(ChromeDriver)\n"
     ]
    }
   ],
   "source": [
    "# Before starting scarping, we should download \"Chromedriver\"\n",
    "\n",
    "# Path to chrome driver\n",
    "ChromeDriver = \"/Users/huanglinchun/Desktop/VS Code Files/chromedriver_mac64/chromedriver.exe\"\n",
    "\n",
    "# launch the driver (it will create an empty google chrome page)\n",
    "driver = webdriver.Chrome(ChromeDriver)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User Imput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter -1 when done.\n",
      "----------\n",
      "----------\n",
      "\n",
      "Routes:\n",
      "TPE => HND\n"
     ]
    }
   ],
   "source": [
    "# get user input for routes\n",
    "'''\n",
    "User Input Order:\n",
    "1. 1st airline departure\n",
    "2. 1st airline destination\n",
    "3. 2nd airline departure\n",
    "4. 2nd airline destination\n",
    ".\n",
    ".\n",
    "In this case, we have two combinations:\n",
    "[NRT TPE][TPE NRT][HND TPE][TPE HND]\n",
    "'''\n",
    "sources = []\n",
    "destinations = []\n",
    "print(\"Please enter -1 when done.\")\n",
    "print(\"-\"*10)\n",
    "while True:\n",
    "    sources.append(input(\"From which city?\\n\"))\n",
    "    if \"-1\" in sources: \n",
    "        sources.pop(-1)\n",
    "        break\n",
    "    destinations.append(input(\"Where to?\\n\"))\n",
    "    if \"-1\" in destinations: \n",
    "        sources.pop(-1)\n",
    "        destinations.pop(-1)\n",
    "        break\n",
    "    print(\"-\"*10)\n",
    "\n",
    "print(\"\\nRoutes:\")\n",
    "for i in range(len(sources)):\n",
    "    print(f\"{sources[i]} => {destinations[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get user input for period (start and end date)\n",
    "start_date = np.datetime64(input('Start Date, Please use YYYY-MM-DD format only '))\n",
    "end_date = np.datetime64(input('End Date, Please use YYYY-MM-DD format only '))\n",
    "days = end_date - start_date\n",
    "num_days = days.item().days\n",
    "\n",
    "'''\n",
    "np.datetime64 object can simply use + - to control date! very smart\n",
    "'''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Functions for Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_airlines(soup):\n",
    "    # 1. Create an empty list for storing airline data\n",
    "    airline = []\n",
    "\n",
    "    # 2. Use \"find_all\" to find all 'div' with class = VY2U in the page(soup)\n",
    "    #    type(airlines) = list\n",
    "    airlines = soup.find_all('div', class_ = \"VY2U\")     # Result Set     \n",
    "    for i in airlines:\n",
    "        # 3. Use for loop to find the text with airline data in each item in \"airlines\"\n",
    "        #    [HTML OBJECT].find(\"{HTML ATTRIBUTE}\", class_=\"\", ...)\n",
    "        a = i.find(class_= 'c_cgF')                      # Tag\n",
    "\n",
    "        #    [HTML OBJECT].text => Return all texts in the object\n",
    "        airline.append(a.text)\n",
    "    return airline\n",
    "    \n",
    "def get_total_stops(soup):\n",
    "    stops_list = []\n",
    "    stops = soup.find_all('div',class_='vmXl-mod-variant-default')\n",
    "\n",
    "    for i in stops:\n",
    "        for j in i.find_all('span',class_='JWEO-stops-text'):\n",
    "            stops_list.append(j.text)\n",
    "    return stops_list\n",
    "\n",
    "def get_price(soup):\n",
    "    prices = []\n",
    "    price = soup.find_all('div',class_='f8F1-price-text-container')\n",
    "\n",
    "    for i in price:\n",
    "        for j in i.find_all('div', class_='f8F1-price-text'):\n",
    "            prices.append(j.text)\n",
    "    return prices\n",
    "\n",
    "def get_duration(soup):\n",
    "    duration_list = []\n",
    "    duration = soup.find_all('div' , class_='xdW8')\n",
    "    for i in duration:\n",
    "        for j in i.find_all('div',class_='vmXl'):\n",
    "            duration_list.append(j.text)\n",
    "    return duration_list"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping Loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "# 4 sources so we have 4 destinations, then this loop will run 4 times.\n",
    "for i in range(len(sources)):\n",
    "    column_names = [\"Airline\", \"Source\", \"Destination\",\"Duration\" ,\"Total stops\", \"Price\",\"Date\"]\n",
    "    df = pd.DataFrame(columns = column_names)\n",
    "\n",
    "    # We set the date from 2022-05-01 to 2023-05-01, so there will be about 366 days\n",
    "    # This loop will run for 366 times\n",
    "    for j in tqdm(range(num_days+1)):\n",
    "        \n",
    "        # close and open driver every 10 days to avoid captcha\n",
    "        driver = webdriver.Chrome(ChromeDriver)\n",
    "        \n",
    "        if j % 10 == 0:\n",
    "            driver.quit()\n",
    "            driver = webdriver.Chrome(ChromeDriver)\n",
    "            #, chrome_options=chromeOptions)\n",
    "        \n",
    "        \n",
    "        # Observing the structures of URL is also an useful approach\n",
    "        url = f\"https://www.kayak.com/flights/{sources[i]}-{destinations[i]}/{start_date+j}\"\n",
    "        driver.get(url)\n",
    "        sleep(8)\n",
    "        \n",
    "        # Oneway = driver.find_elements(By.XPATH, \"//*[contains(text(), 'One-way')]\")\n",
    "        \n",
    "        # click show more button to get all flights\n",
    "        \n",
    "        # find_element is a function of \"WebDriver\", not BS4\n",
    "        try:\n",
    "            show_more_button = driver.find_element(By.CLASS_NAME, \"ULvh-button\")\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        while True:\n",
    "            try:\n",
    "                show_more_button.click()\n",
    "                driver.implicitly_wait(10)\n",
    "            except:\n",
    "                break\n",
    "        \n",
    "        # Use \"BeautifulSoup\" to get web page parser\n",
    "        # BeautifulSoup({WEBDRIVER}.page_source, 'html.parser')\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        airlines = get_airlines(soup)             # Return a list of airline data\n",
    "        total_stops = get_total_stops(soup)       # Return a list of total stop data\n",
    "        prices = get_price(soup)                  # Return a list of price data\n",
    "        duration = get_duration(soup)             # Return a list of duration data\n",
    "        \n",
    "        # Use df.append({COLUMN: ARRAYS, ...})\n",
    "        df = df.append(pd.DataFrame({\n",
    "            'Airline': airlines,\n",
    "            'Duration': duration,\n",
    "            'Total stops' : total_stops,\n",
    "            'Price' : prices,\n",
    "            'Date' : start_date+j\n",
    "                                    }))\n",
    "    \n",
    "    # Because all of the sources and destinations in this dataframe are the same\n",
    "    df['Source'] = sources[i]\n",
    "    df['Destination'] = destinations[i]\n",
    "    df = df.replace('\\n','', regex=True)\n",
    "    df = df.reset_index(drop = True)\n",
    "    \n",
    "    # save data as csv file for each route\n",
    "    df.to_csv(f'{sources[i]}_{destinations[i]}.csv',index=False)\n",
    "    print(f\"Succesfully saved {sources[i]} => {destinations[i]} route as {sources[i]}_{destinations[i]}.csv \")\n",
    "    \n",
    "driver.quit()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping Testing Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gl/stf2yn_54sdd_k_jlfmc4nvr0000gn/T/ipykernel_40576/1774845910.py:1: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(ChromeDriver)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Jetstar Japan', 'Peach', 'Tigerair Taiwan', 'VietJet Air', 'Tigerair Taiwan', 'VietJet Air', 'VietJet Air', 'China Airlines', 'Scoot', 'Jeju Air', 'Asiana Airlines', 'Asiana Airlines', 'Asiana Airlines', 'Asiana Airlines', 'Hahn Air Systems']\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome(ChromeDriver)\n",
    "url = \"https://www.kayak.com/flights/TPE-NRT/2023-05-12\"\n",
    "driver.get(url)\n",
    "sleep(5)\n",
    "\n",
    "soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "price_1 = get_airlines(soup)\n",
    "print(price_1)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
